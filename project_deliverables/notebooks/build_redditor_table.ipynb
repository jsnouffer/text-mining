{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import praw\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from elasticsearch import helpers\n",
    "scan = helpers.scan\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Reddit API and ElasticSearch Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/api/v1/authorize?client_id=Cz8OU1vxajnWDw&duration=permanent&redirect_uri=http%3A%2F%2Flocalhost%3A8080&response_type=code&scope=identity&state=...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'localhost', 'port': 9200}])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id='Cz8OU1vxajnWDw',\n",
    "                     client_secret='5qax29ZPI2_Rdjc1TsXXEypFduk',\n",
    "                     redirect_uri='http://localhost:8080',\n",
    "                     user_agent='my user agent')\n",
    "\n",
    "print(reddit.auth.url(['identity'], '...', 'permanent'))\n",
    "\n",
    "es = Elasticsearch([{'host':'localhost','port':9200}])\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab popular subreddits from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for subreddit in reddit.subreddits.popular():\n",
    "    count += 1\n",
    "    doc = {\n",
    "        \"id\": subreddit.display_name,\n",
    "        \"title\": subreddit.title,\n",
    "        \"description\": subreddit.public_description,\n",
    "        \"subscribers\": subreddit.subscribers,\n",
    "        \"created\": datetime.fromtimestamp(subreddit.created_utc).isoformat(),\n",
    "        \"language\": subreddit.lang,\n",
    "        \"category\": subreddit.advertiser_category,\n",
    "        \"redditors_indexed\": False\n",
    "    }\n",
    "    \n",
    "    # Ingest into Elastic\n",
    "    es.index(index = 'subreddits.popular', id = subreddit.display_name, body = doc)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab up-to 1000 comments for each subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "NotFoundError(404, 'search_phase_execution_exception', 'No search context found for id [861794]')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-08001fb4a3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     index = 'subreddits.popular')\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msubreddit_doc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0msubreddit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubreddit_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/helpers/actions.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(client, query, scroll, raise_on_error, preserve_order, size, request_timeout, clear_scroll, scroll_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                     )\n\u001b[1;32m    457\u001b[0m             \u001b[0mscroll_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"scroll_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscroll_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scroll\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscroll\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mscroll_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0mscroll_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_scroll_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/client/__init__.py\u001b[0m in \u001b[0;36mscroll\u001b[0;34m(self, body, params)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m         return self.transport.perform_request(\n\u001b[0;32m-> 1315\u001b[0;31m             \u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/_search/scroll\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m         )\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m                 )\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             )\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         self.log_request_success(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/connection/base.py\u001b[0m in \u001b[0;36m_raise_error\u001b[0;34m(self, status_code, raw_data)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         raise HTTP_EXCEPTIONS.get(status_code, TransportError)(\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: NotFoundError(404, 'search_phase_execution_exception', 'No search context found for id [861794]')"
     ]
    }
   ],
   "source": [
    "redditors = 'redditors'\n",
    "\n",
    "try:\n",
    "    es.indices.create(index = redditors)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "results = scan(es,         \n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"term\": {\n",
    "                \"redditors_indexed\": {\n",
    "                    \"value\": False\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    index = 'subreddits.popular')\n",
    "\n",
    "for subreddit_doc in results:    \n",
    "    subreddit = reddit.subreddit(subreddit_doc['_id'])\n",
    "    for comment in subreddit.comments(limit = 1000):\n",
    "        doc = {}\n",
    "        \n",
    "        author = comment.author\n",
    "        \n",
    "        try:\n",
    "            if not author or not author.name or not author.fullname:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if (es.exists(index = redditors, id = author.name)):\n",
    "            doc = es.get(index = redditors, id = author.name)['_source']\n",
    "        \n",
    "        if 'name' not in doc.keys():\n",
    "            doc['name'] = author.name\n",
    "            \n",
    "        if 'object_id' not in doc.keys():\n",
    "            doc['object_id'] = author.fullname\n",
    "            \n",
    "        if 'categories' not in doc.keys(): \n",
    "            doc['categories'] = []\n",
    "        \n",
    "        if subreddit.advertiser_category not in doc['categories']:\n",
    "            doc['categories'].append(subreddit.advertiser_category)\n",
    "        \n",
    "        if 'subreddits' not in doc.keys(): \n",
    "            doc['subreddits'] = []\n",
    "        \n",
    "        if subreddit.display_name not in doc['subreddits']:\n",
    "            doc['subreddits'].append(subreddit.display_name)\n",
    "        \n",
    "        if 'trophies' not in doc.keys():\n",
    "            doc['trophies'] = []\n",
    "        \n",
    "        for trophy in author.trophies():\n",
    "            if trophy.name not in doc['trophies']:\n",
    "                doc['trophies'].append(trophy.name)\n",
    "        \n",
    "        es.index(index = redditors, id = author.name, body = doc)\n",
    "    \n",
    "    update = {\n",
    "        \"doc\": {\n",
    "              \"redditors_indexed\": True\n",
    "        }\n",
    "    }\n",
    "    es.update(index = 'subreddits.popular', id = subreddit_doc['_id'], body = update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
