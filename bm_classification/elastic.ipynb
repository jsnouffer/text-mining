{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading E\n",
      "loading S\n",
      "loading T\n",
      "loading J\n"
     ]
    }
   ],
   "source": [
    "%run classifier.py\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "scan = helpers.scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'localhost', 'port': 9200}])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch([{'host':'localhost','port':9200}])\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(es, author, index_prefix, sublisting, all_classifier):\n",
    "    classifier = None\n",
    "    idx = index_prefix + '.' + sublisting\n",
    "    print(idx)\n",
    "    src_results = scan(es, scroll='10m',    \n",
    "        query = {\n",
    "            \"query\": {\n",
    "                \"query_string\" : {\n",
    "                    \"query\" : author,\n",
    "                    \"default_field\" : \"author\"\n",
    "                }\n",
    "            }\n",
    "        }, index = idx)\n",
    "    \n",
    "    count=0\n",
    "    for src_doc in src_results:\n",
    "        count = count + 1\n",
    "        if count >= 100:\n",
    "            break # limit to 100 comments for performance\n",
    "        \n",
    "        if classifier is None:\n",
    "            classifier = Classifier() \n",
    "        text = src_doc['_source']['text_body']\n",
    "        classifier.preprocess(text, web=False)\n",
    "        all_classifier.preprocess(text, web=False)\n",
    "        \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kazzack\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "src_index = 'redditors'\n",
    "dest_index = 'comments'\n",
    "comment_sublistings = ['controversial', 'hot', 'new', 'top'] \n",
    "src_results = es.search(scroll='360m',\n",
    "    body = {\n",
    "    \"query\": {\n",
    "      \"function_score\": {\n",
    "        \"query\": {\n",
    "          \"bool\": {\n",
    "            \"must\": [\n",
    "              {\n",
    "                \"bool\": {\n",
    "                  \"must_not\": [\n",
    "                    {\n",
    "                      \"exists\": {\n",
    "                        \"field\": \"bm\"\n",
    "                      }\n",
    "                    }\n",
    "                  ]\n",
    "                }\n",
    "              },\n",
    "              {\n",
    "                \"term\": {\n",
    "                  \"comments_indexed\": {\n",
    "                    \"value\": True\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        \"random_score\": {\n",
    "            \"seed\": random.randint(1,1000)\n",
    "        },\n",
    "        \"boost_mode\": \"replace\"\n",
    "      }\n",
    "    }\n",
    "  }, index = src_index, size=1000)\n",
    "\n",
    "for src_doc in src_results['hits']['hits']:\n",
    "    author_doc = src_doc['_source']\n",
    "    print(author_doc['name'])\n",
    "    break\n",
    "    controversial = None\n",
    "    hot = None\n",
    "    new = None\n",
    "    top = None\n",
    "    update = None\n",
    "    \n",
    "    all_classifier = Classifier()\n",
    "    for sublisting in comment_sublistings:\n",
    "        classifier = classify(es, author_doc['name'], dest_index, sublisting, all_classifier)\n",
    "        if classifier is not None:\n",
    "            if update is None:\n",
    "                update = { \"doc\": { \"bm\": {} } }\n",
    "            \n",
    "            res = more_magic(classifier)\n",
    "            res['type'] = ''.join([key[0] for key in res.keys()])\n",
    "            update['doc']['bm'][sublisting] = res\n",
    "    if update is not None:\n",
    "        overall = more_magic(all_classifier)\n",
    "        overall['type'] = ''.join([key[0] for key in overall.keys()])\n",
    "        update['doc']['bm']['overall'] = overall\n",
    "        es.update(index = src_index, id = src_doc['_id'], body = update)\n",
    "    else:\n",
    "        update = { \"doc\": { \"bm\": {} } }\n",
    "        es.update(index = src_index, id = src_doc['_id'], body = update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
